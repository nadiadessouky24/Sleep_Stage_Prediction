{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3035b0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import medfilt\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f32ef76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate_models(models, X_val, y_val, method='isotonic', cv=5):\n",
    "    \"\"\"\n",
    "    Calibrate each pre-trained classifier on (X_val, y_val).\n",
    "    \"\"\"\n",
    "    calibrated = {}\n",
    "    for name, clf in models.items():\n",
    "        calibrator = CalibratedClassifierCV(clf,method=method, cv=cv)\n",
    "        calibrated[name] = calibrator.fit(X_val, y_val)\n",
    "    return calibrated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1455a7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_probas(calibrated_models, X_test):\n",
    "    \"\"\"\n",
    "    Soft-voting ensemble: average probability outputs.\n",
    "    \n",
    "    Returns ensembled probabilities and the class labels.\n",
    "    \"\"\"\n",
    "    probas = [clf.predict_proba(X_test) for clf in calibrated_models.values()]\n",
    "    proba_ens = np.mean(probas, axis=0)\n",
    "    classes = list(calibrated_models.values())[0].classes_\n",
    "    return proba_ens, classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc271c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_labels(proba_ens, classes, smoothing=True):\n",
    "    \"\"\"\n",
    "    Convert ensembled probabilities to discrete labels.\n",
    "    \n",
    "    Applies argmax + optional median smoothing.\n",
    "    \"\"\"\n",
    "    idx = np.argmax(proba_ens, axis=1)\n",
    "    y_pred = np.array(classes)[idx]\n",
    "    if smoothing:\n",
    "        y_pred = medfilt(y_pred, kernel_size=3)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "322c9313",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predictions(y_true, y_pred, labels, target_names):\n",
    "    \"\"\"\n",
    "    Compute and print confusion matrix, classification report, and F1 scores.\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    print(\"Confusion Matrix (rows=true, cols=pred):\")\n",
    "    print(cm)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred,labels=labels, target_names=target_names, digits=3))\n",
    "    f1_mac = f1_score(y_true, y_pred, average='macro', labels=labels)\n",
    "    f1_mic = f1_score(y_true, y_pred, average='micro')\n",
    "    print(f\"Macro-averaged F1: {f1_mac:.3f}\")\n",
    "    print(f\"Micro-averaged F1: {f1_mic:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3631d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (rows=true, cols=pred):\n",
      "[[ 8  0  5  6  1]\n",
      " [ 2  6  5  7  0]\n",
      " [ 2  1 10  5  2]\n",
      " [ 0  3  2 12  3]\n",
      " [ 4  2  7  4  3]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Wake      0.500     0.400     0.444        20\n",
      "          N1      0.500     0.300     0.375        20\n",
      "          N2      0.345     0.500     0.408        20\n",
      "          N3      0.353     0.600     0.444        20\n",
      "         REM      0.333     0.150     0.207        20\n",
      "\n",
      "    accuracy                          0.390       100\n",
      "   macro avg      0.406     0.390     0.376       100\n",
      "weighted avg      0.406     0.390     0.376       100\n",
      "\n",
      "Macro-averaged F1: 0.376\n",
      "Micro-averaged F1: 0.390\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "   #dummy data\n",
    "    X, y = make_classification(\n",
    "        n_samples=500,\n",
    "        n_features=3,\n",
    "        n_informative=3,\n",
    "        n_redundant=0,\n",
    "        n_classes=5,\n",
    "        n_clusters_per_class=1,\n",
    "        random_state=42\n",
    "    )\n",
    "    y = np.where(y == 4, 5, y)\n",
    "    \n",
    "    X_train, X_temp, y_train, y_temp = train_test_split( X, y, test_size=0.4, stratify=y, random_state=0 )\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=0 )\n",
    "\n",
    "    models = {\n",
    "        'svm': SVC(probability=True, random_state=0),\n",
    "        'rf':  RandomForestClassifier(n_estimators=100, random_state=0),\n",
    "        'lr':  LogisticRegression(max_iter=1000, random_state=0)\n",
    "    }\n",
    "    for clf in models.values():\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "    #enhancement\n",
    "    calibrated = calibrate_models(models, X_val, y_val,method='isotonic', cv=5)\n",
    "    proba_ens, classes = ensemble_probas(calibrated, X_test)\n",
    "    y_pred = get_final_labels(proba_ens, classes, smoothing=True)\n",
    "\n",
    "    #Evaluate\n",
    "    labels       = [0,1,2,3,5]\n",
    "    target_names = ['Wake','N1','N2','N3','REM']\n",
    "    evaluate_predictions(y_test, y_pred, labels, target_names)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
